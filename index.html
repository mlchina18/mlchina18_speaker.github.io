
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!-- saved from url=(0047)http://people.tuebingen.mpg.de/causal-learning/ -->

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" ""><HTML><HEAD><META 

content="IE=5.0000" http-equiv="X-UA-Compatible">

 <TITLE>MLChina'18</TITLE> 

<META http-equiv="Content-Type" content="text/html; charset=gb2312"><LINK href="style.css" 

rel="stylesheet"> 

<SCRIPT type="text/javascript">



  var _gaq = _gaq || [];

  _gaq.push(['_setAccount', 'UA-31103843-1']);

  _gaq.push(['_trackPageview']);



  (function() {

    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;

    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';

    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);

  })();



</SCRIPT>



<META name="GENERATOR" content="MSHTML 10.00.9200.16521">

<style type="text/css">

<!--

.style1 {

	font-size: 36px;

	font-weight: bold;

}

.style3 {font-family: Arial, Helvetica, sans-serif}

.style5 {

	font-family: Arial, Helvetica, sans-serif;

	color: #9900FF;

	font-size: 32px;

}

.style55 {

	font-family: Arial, Helvetica, sans-serif;

	color: #9900FF;

	font-size: 14px;

}

.style6 {

	font-size: 14px;

	color: #0000FF;

}

.style8 {

	font-family: Arial, Helvetica, sans-serif;

	font-size: 18px;

	color: #000000;

	font-weight: bold;

}

.style9 {

	font-family: Arial, Helvetica, sans-serif;

	font-size: 14px;

	color: #000000;

}

.style12 {font-size: 14px}

.style13 {color: #000000}

.style14 {font-family: Arial, Helvetica, sans-serif; font-size: 14px; }

-->

</style>

</HEAD> 

<BODY>

<TABLE width="902" border="0" align="center" cellpadding="0" cellspacing="0">

  <TBODY>

  <TR>

    <TD height="8" colspan="3"></TD></TR>

  <TR>

    <TD colspan="3"><div align="center"><IMG src="bj.jpg" width="1000" height="170"></div></TD>

  </TR>

  <TR>

    <TD height="10" colspan="3"><div align="center" class="style1">

      <p><span class="style5">The ACML 2018 Workshop on Machine Learning in China (MLChina'18) </span><br>

        <span class="style55">Beijing Jiaotong University<br/>

November 14 - 16, 2018</span><br>

      </p>

      </div></TD>

  </TR>

  <TR align="center" valign="top">

    <TD width="4"><BR></TD>

    <TD width="981" align="center" valign="top">

      <TABLE width="921" border="0" align="center" cellpadding="0" cellspacing="5">

        <TBODY>

        <TR valign="top">

          <TD width="129" align="center" bgcolor="#FFFFFF"><DIV class="style6" id="menu" align="left">

            <p><a href="https://mlchina18.github.io/">Home</a>            </p>

            <p><b>Invited 

              Speakers</b></p>

            <p><a href="https://mlchina18.github.io/program/">Technical Program</a>            </p>

            <p ><a href="https://mlchina18.github.io/chinese/">Chinese Version (中文版)</a></p>

          </div></TD>

          <TD width="16"><BR></TD>

          <TD width="756" align="left">

            <p align="justify" class="style8">Keynote Speakers (sorted in alphabetic order) </p>

            <ul>
              <li class="style9"><b>Prof. <a href="http://www.klmp.pku.edu.cn/Faculty/FacultyDetail.aspx?FacultyID=90" target="_blank">Zhouchen Lin</a></b>, Peiking University, China</li>
              <p align="justify" class="style9">Title: First-Order Optimization Methods in Machine Learning</p>
	      <p align="justify" class="style9">Abstract: Optimization is a key component in machine learning. When problems scale up, normally only first-order optimization methods can be used in practice. 
		      In this talk I will briefly review some advances in the first-order optimization methods in machine learning. If time permits, I will also introduce some of my recent work on first order optimization.</p>
		<p align="justify" class="style9">Bio: Zhouchen Lin is currently a professor with the Key Laboratory of Machine Perception, School of Electronics Engineering and Computer Science, Peking University. 
		      His research interests include computer vision, image processing, machine learning, pattern recognition, and numerical optimization. He is an area chair of CVPR 2014/2016/2019, 
		      ICCV 2015, NIPS 2015/2018 and AAAI 2019, and a senior program committee member of AAAI 2016/2017/2018 and IJCAI 2016/2018. He is an associate editor of the IEEE Transactions on Pattern Analysis 
		      and Machine Intelligence and the International Journal of Computer Vision. He is a Fellow of IAPR and IEEE.
		    </p>

              </ul>

            <p align="justify" class="style8">Invited Speakers (sorted in alphabetic order) (tentative)</p>

              <ul>
                <li class="style9"><b>Prof. <a href="http://www.cis.pku.edu.cn/faculty/vision/wangliwei/" target="_blank">Liwei Wang</a></b>, Peiking University, China</li>
                <Br/>
		<p align="justify" class="style9">Title: Towards Understanding Deep Learning: Two Theories of Stochastic Gradient Langevin Dynamics</p>
	        <p align="justify" class="style9">Abstract: Deep learning has achieved great success in many applications. However, deep learning is a mystery from a learning theory point of view. In all typical deep learning tasks,
			the number of free parameters of the networks is at least an order of magnitude larger than the number of training data. This rules out the possibility of using any model complexity-based learning theory
			(VC dimension, Rademacher complexity etc.) to explain the good generalization ability of deep learning. Indeed, the best paper of ICLR 2017 “Understanding Deep Learning Requires Rethinking Generalization”
			conducted a series of carefully designed experiments and concluded that all previously well-known learning theories fail to explain the phenomenon of deep learning.
		        In this talk, I will give two theories characterizing the generalization ability of Stochastic Gradient Langevin Dynamics (SGLD), a variant of the commonly used Stochastic Gradient Decent (SGD) algorithm 
			in deep learning. Building upon tools from stochastic differential equation and partial differential equation, I show that SGLD has strong generalization power. The theory also explains several 
			phenomena observed in deep learning experiments.</p>
		<p align="justify" class="style9">Bio: Liwei Wang is a professor of School of Electronics Engineering and Computer Sciences, Peking University. His main research interest is machine learning theory and 
			has published more than 100 papers on top conferences and journals. He was the first Asian researcher who was named among “AI’s 10 to Watch”. He served as the Area Chair of NIPS and 
			the Associate Editor of PAMI.
		    </p>

                <li class="style9"><b>Prof. <a href="http://lamda.nju.edu.cn/yuy/" target="_blank">Yang Yu </a></b>, Nanjing University, China</li><br/>


                <li class="style9"><b>Prof. <a href="http://bigml.cs.tsinghua.edu.cn/~jun/index.shtml" target="_blank">Jun Zhu</a></b>, Tsinghua University, China</li><br/>

                <li class="style9"><b>Prof. <a href="http://homepage.hit.edu.cn/wangmengzuo" target="_blank">Wangmeng Zuo</a></b>, Harbin Institute of Technology, China</li><br/>
		      <p align="justify" class="style9">Title: Guided and transfer learning with multiple domains of visual data</p>
	        <p align="justify" class="style9">Abstract: In many vision learning tasks, we may have multiple domain data in the training or testing stage.  In general, better learning performance is expected to be 
			attained by properly exploiting multiple domains of visual data. In this talk, we specifically consider two cases. First, when multiple domains of data are available in both training and testing, 
			several guided network architectures are designed for making use of the high quality image in domain to enhance the low quality (degraded) image in another domain. Based on the spatial correlation 
			between guided and degraded images, we design an analysis model guided learning deep architecture and a deformable flow guidance learning network, and apply them for guided depth image enhancement 
			and guided face restoration. Second, when the multiple domains (e.g., source and target) are only available in training, domain adaptation, domain translation, feature consistency can be developed 
			for exploiting multiple domains of data to enhance the model learned for target domain. Several architectures are presented for improved domain transfer by addressing class weight bias and minimizing 
			distribution discrepancy.</p>
		<p align="justify" class="style9">Bio: Wangmeng Zuo received the Ph.D. degree in computer application technology from the Harbin Institute of Technology, Harbin, China, in 2007.
                        He is currently a Professor in the School of Computer Science and Technology, Harbin Institute of Technology. His current research interests include image enhancement and restoration, object detection, visual tracking, and image classification.
                        He has published over 70 papers in top-tier academic journals and conferences.
                        He has served as a Tutorial Organizer in ECCV 2016, an Associate Editor of the IET Biometrics and Journal of Electronic Imaging, and the Guest Editor of Neurocomputing, Pattern Recognition, IEEE Transactions on Circuits and Systems for Video Technology, 
			and IEEE Transactions on Neural Networks and Learning Systems.
		    </p>
		<li class="style9"><b>Prof. <a href="http://computer.bjtu.edu.cn/cms/staff/8249/?cat=14" target="_blank">Liping Jing</a></b>, Beijing Jiaotong University, China</li>
		    <p align="justify" class="style9">Title:Representation learning for multi-modal heterogeneous data</p>
	            <p align="justify" class="style9">Abstract: With the development of data collection techniques, multi-modal data analysis becomes an emerging research direction to improve the learning performance. Existing work has shown that leveraging multi-modal information
			is able to provide a rich and comprehensive description. For example, an image can be characterized by color, edge, texture and etc; a web-page can be represented by both page-text and hyperlinks pointing to them. There may be multiple measurement 
			modalities such as simultaneously recorded images, annotation tags or texts in different languages. Each modality generates one kind of description about the object, and various descriptions in different modalitiess usually characterize different 
			and partially information about the objects. One of the core problems is how to sufficiently represent multi-modal heterogeneous data in the analysis. In this talk, we will focus on our recent work about multi-modal heterogeneous data representation learning. </p>
		    <p align="justify" class="style9">Bio: Liping Jing received the Ph.D degree in applied mathematics from the University of Hong Kong in 2007. She was a Research Associate with Hong Kong Baptist University, Hong Kong, a Research Fellow with University of Texas at Dallas, 
			USA, from 2007 to 2008, and a Vistiting Scholoar with ICSI and the AMPLab, University of California at Berkeley, USA, from 2015 to 2016. Her research interests include machine learning and its applications. She served as a regular reviewer and program committee 
			member for a number of international journals and conferences. She is PI of several projects including the National Science Fund for Excellent Young Scholars.
		    </p>
		</ul> 

              <p>&nbsp;</p></TD>

      </TR></TBODY></TABLE></TD>

    <TD width="15"></TD></TR></TBODY></TABLE>

<P><BR><BR><BR></P></BODY></HTML>

